{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "93e4bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d16e6d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for reproducibility \n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "86214d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    \"\"\"\n",
    "    A simple artificial neuron that computes a weighted sum of its inputs, applies an activation function, and produces an output.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_inputs):\n",
    "        \"\"\"\n",
    "        Initialize the neuron with random weights and bias.\n",
    "        \"\"\"\n",
    "\n",
    "        # xavier initialization for weights\n",
    "        limit = 1/math.sqrt(num_inputs)\n",
    "        self.weights = [np.random.uniform(-limit,limit) for _ in range(num_inputs)]\n",
    "\n",
    "        # Bias initialization\n",
    "        self.bias = np.random.uniform(-limit, limit)\n",
    "\n",
    "        self.inputs = None\n",
    "        self.output = None\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Compute output of the neurons in the layer given the inputs.\n",
    "        \"\"\"\n",
    "\n",
    "        # preserve copy of original inputs \n",
    "        self.inputs = inputs[:]\n",
    "\n",
    "        # compute weighted sum\n",
    "        weighted_sum = sum(w*x  for w,x in zip(self.weights, inputs)) + self.bias\n",
    "\n",
    "        # applying ReLU by default\n",
    "        self.output = max(0, weighted_sum)\n",
    "\n",
    "        return self.output\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"String representation of the neuron\"\"\"\n",
    "        return f\"Neuron(weights={[round(w, 3) for w in self.weights]}, bias={round(self.bias, 3)})\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9f8980e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \"\"\"\n",
    "    A layer of neurons in a neural network.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_neurons, num_inputs_per_neuron, is_output=False):\n",
    "        \"\"\"\n",
    "        Initialize the layer with given number of neurons, each with specified number of inputs.\n",
    "\n",
    "        Args: \n",
    "            num_neurons (int): Number of neurons in the layer.\n",
    "            num_inputs_per_neuron (int): Number of inputs each neuron receives.\n",
    "            is_output (bool): Flag indicating if this layer is the output layer.\n",
    "        \"\"\"\n",
    "\n",
    "        self.num_neurons = num_neurons\n",
    "        self.num_inputs_per_neuron = num_inputs_per_neuron\n",
    "        self.is_output = is_output\n",
    "\n",
    "        # creating neurons for the layer\n",
    "        self.neurons = [Neuron(num_inputs_per_neuron) for _ in range(num_neurons)]\n",
    "        self.inputs = None\n",
    "        self.outputs = None\n",
    "\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forwards pass through layers sequentially by computing outputs of all neurons in the layer.\n",
    "        \"\"\"\n",
    "\n",
    "        self.inputs = inputs[:]\n",
    "\n",
    "        # get output from each neuron\n",
    "        self.outputs = [neuron.forward(inputs) for neuron in self.neurons]\n",
    "\n",
    "        return self.outputs\n",
    "\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"String representation of the layer\"\"\"\n",
    "        layer_type = \"Output\" if self.is_output else \"Hidden\"\n",
    "        return f\"{layer_type} Layer ({self.num_neurons} neurons, {self.num_inputs_per_neuron} inputs each)\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b02b9ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \"\"\"\n",
    "        Neural Network consisting of multiple layers.\n",
    "        Basic idea of Multi-Layer perceptron\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes):\n",
    "\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.num_layers = len(layer_sizes)\n",
    "        self. layers = []\n",
    "\n",
    "        for i in range(1, self.num_layers):\n",
    "            num_neurons = layer_sizes[i]\n",
    "            num_inputs_per_neuron = layer_sizes[i-1]\n",
    "            is_output = (i == self.num_layers - 1)\n",
    "\n",
    "            layer = Layer(num_neurons, num_inputs_per_neuron, is_output)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass through the entire network.\n",
    "        \"\"\"\n",
    "\n",
    "        for layer in self.layers:\n",
    "            inputs = layer.forward(inputs)\n",
    "\n",
    "        return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bb8ca4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Architecture:\n",
      "Layer 1: Hidden Layer (3 neurons, 2 inputs each)\n",
      "  Neuron 1: Neuron(weights=[-0.177, 0.637], bias=0.328)\n",
      "  Neuron 2: Neuron(weights=[0.14, -0.486], bias=-0.486)\n",
      "  Neuron 3: Neuron(weights=[-0.625, 0.518], bias=0.143)\n",
      "Layer 2: Output Layer (1 neurons, 3 inputs each)\n",
      "  Neuron 1: Neuron(weights=[0.24, -0.554, 0.543], bias=0.384)\n"
     ]
    }
   ],
   "source": [
    "nw = Network([2,3,1])\n",
    "\n",
    "print(\"Network Architecture:\")\n",
    "for i, layer in enumerate(nw.layers):\n",
    "    print(f\"Layer {i+1}: {layer}\")\n",
    "    for j, neuron in enumerate(layer.neurons):\n",
    "        print(f\"  Neuron {j+1}: {neuron}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e95bda5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network output: [0.21062314276556207]\n",
      "\n",
      "Layer by layer:\n",
      "Layer 1 output: [0, 0.3129595241608698, 0]\n",
      "Layer 2 (final) output: [0.21062314276556207]\n"
     ]
    }
   ],
   "source": [
    "input_data = [0.5, -1.5]\n",
    "output = nw.forward(input_data)\n",
    "print(f\"Network output: {output}\")\n",
    "\n",
    "# You can also test layer by layer:\n",
    "print(\"\\nLayer by layer:\")\n",
    "layer1_output = nw.layers[0].forward(input_data)\n",
    "print(f\"Layer 1 output: {layer1_output}\")\n",
    "\n",
    "layer2_output = nw.layers[1].forward(layer1_output)\n",
    "print(f\"Layer 2 (final) output: {layer2_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73ebbc3",
   "metadata": {},
   "source": [
    "## Forward Pass:\n",
    "\n",
    "Consider an architeure with 3 inputs, hidden1 with 3 neurons , hidden 2 with 2 neurons and output layer with 1 neuron.\n",
    "\n",
    "prediction = sigma(W@X + b)\n",
    "\n",
    "Where W is weights matrix, X is input vector, b is bias vector and sigma is activation function (ReLU here).\n",
    "\n",
    "matrix form:\n",
    "layer 1:\n",
    "| w11 w12 w13 |     | x1 |     | b11 |\n",
    "| w21 w22 w23 |  @  | x2 |  +  | b12 |\n",
    "| w31 w32 w33 |     | x3 |     | b13 |\n",
    "=>\n",
    "o11 = sigma(w11*x1 + w12*x2 + w13*x3 + b11)\n",
    "o21 = sigma(w21*x1 + w22*x2 + w23*x3 + b12)\n",
    "o31 = sigma(w31*x1 + w32*x2 + w33*x3 + b13)\n",
    "\n",
    "layer 2:\n",
    "| w11 w12 |     | o11 |     | b21 |\n",
    "| w21 w22 |  @  | o21 |  +  | b22 |\n",
    "| w31 w32 |     | o31 |     \n",
    "=>\n",
    "o12 = sigma(w11*o11 + w12*o21 + b21)\n",
    "o22 = sigma(w21*o11 + w22*o21 + b22)\n",
    "\n",
    "\n",
    "layer 3:\n",
    "|w11|     | o12 |     | b31 |\n",
    "|w21|  @  | o22 |  +  \n",
    "=> \n",
    "o31 (yhat) = sigma(w11*o12 + w21*o22 + b31)\n",
    "\n",
    "\n",
    "**What is happening in forward function?**\n",
    "\n",
    "- network.forward(X) takes input X and passes it through each layer sequentially.\n",
    "- For each layer, layer.forward(inputs) it takes the current inputs, obtains outputs from all the neurons in that layer, and uses these outputs as inputs for the next layer.\n",
    "- neuron.forward(inputs) computes the weighted sum of inputs plus bias, applies the activation function, and returns the output for that neuron.\n",
    "- Finally, it returns the output from the last layer as the network's prediction.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
